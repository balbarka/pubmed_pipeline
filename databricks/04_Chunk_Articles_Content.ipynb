{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0015194f-f390-4b43-a01c-7aabba831282",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Article Chunking with `unstructured`\n",
    "\n",
    "We will use [unstructured](https://unstructured.io/) for our primary chunking strategy. We are going to use this for the actual body content and it is common to change the arguments of the unstructured [partitioning](https://docs.unstructured.io/open-source/core-functionality/partitioning) functions upon future iterations where we are improving our Dataset curation for pre-training or fine-tuning or our chunking strategy for our VS index.\n",
    "\n",
    "**NOTE**: Since we are working with XML data we are going to use the [partition-xml](https://docs.unstructured.io/open-source/core-functionality/partitioning#partition-xml) function. There are many libraries out there that can make use of the xml tags we left in our body column and they can excluded easily with regex or opensource xml parsing library. Thus, we left the xml in the body to allow for discovery of new / different parsing strategies in the future. Chunking strategies are becoming more and more relavant in improving RAG performance.\n",
    "\n",
    "**NOTE**: YES. We could have used [partition-xml](https://docs.unstructured.io/open-source/core-functionality/partitioning#partition-xml) function to parse from file instead of from the `curated_articles` delta table. Similar to the above note, we did this to make future iterative improvements faster as reading text from file in blob storage has a much larger I/O preformance cost. This was a deliberate architecture decision for future enhancements, not just to conform to a [Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture)... although we are doing that as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a926da3-b290-4469-81f1-8a44eb1d7db8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.dropdown(name=\"FILE_TYPE\", defaultValue=\"xml\", choices=[\"xml\", \"text\"])\n",
    "FILE_TYPE = dbutils.widgets.get(\"FILE_TYPE\")\n",
    "dbutils.widgets.dropdown(name=\"INSPECT_CONTENT\", defaultValue=\"true\", choices=[\"true\", \"false\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a49b95f-77fc-4dbc-8e16-730f76721959",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%pip install unstructured\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48c061c8-89e2-4163-93a2-038f14770a71",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./_resources/pubmed_pipeline_config $RESET_ALL_DATA=false $DISPLAY_CONFIGS=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb3ba469-557f-4cbf-8fec-7160650edf15",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a UDF that will chunk our article bodies\n",
    "#TODO: check if we have multi-language sources\n",
    "#TODO: evaluate using pandas UDF\n",
    "\n",
    "from unstructured.partition.xml import partition_xml\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def chunk_xml_body(body: str, attrs: dict):\n",
    "    root = ET.Element('root', attrib=attrs)\n",
    "    root.text = body\n",
    "    body_elements = partition_xml(text=str(ET.tostring(root, encoding='utf-8'), 'UTF-8'),\n",
    "                                  xml_keep_tags = False,\n",
    "                                  encoding='utf-8',\n",
    "                                  include_metadata=False,\n",
    "                                  languages=['eng',],\n",
    "                                  date_from_file_object=None,\n",
    "                                  chunking_strategy='by_title',\n",
    "                                  multipage_sections=True,\n",
    "                                  combine_text_under_n_chars=300,\n",
    "                                  new_after_n_chars=1400,\n",
    "                                  max_characters=1250)\n",
    "    body_chunks = [be.text for be in body_elements if len(be.text) >= 110]\n",
    "    return body_chunks\n",
    "\n",
    "chunk_xml_body_udf = udf(chunk_xml_body, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2029bfef-4b49-45ff-9b6a-05e9e67d6ab8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "The proposed schema for our target table is:\n",
    "  TODO: include DDL from CREATE_TABLE_processed_articles_content.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed97c43b-8207-4d32-8f4d-479942f58e5a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, concat\n",
    "from pyspark.sql.functions import xpath_string, explode, posexplode\n",
    "\n",
    "# This includes limit for discussion, real workload will not include a limit\n",
    "content_src = pubmed.curated_articles.df \\\n",
    "                    .withColumn('contents', chunk_xml_body_udf('body', 'attrs')) \\\n",
    "                    .select(col('AccessionID').alias('pmid'),\n",
    "                            xpath_string(col('front'),lit('front/article-meta/title-group/article-title')).alias('title'),\n",
    "                            xpath_string(col('front'),lit('front/journal-meta/journal-title-group/journal-title')).alias('journal'),\n",
    "                            lit('NEED DESIRED CITATION FORMAT').alias('citation'),\n",
    "                            xpath_string(col('front'),lit('front/article-meta/pub-date/year')).alias('year'),\n",
    "                            posexplode('contents').alias('content_pos', 'content')) \\\n",
    "                    .withColumn('id', concat(col('pmid'), lit('-'), col('content_pos'))) \\\n",
    "                    .drop('content_pos') \\\n",
    "                    .alias('src')\n",
    "content_src.createOrReplaceTempView('content_src')\n",
    "\n",
    "#display(content_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34cd55ae-cb02-4c8e-a3a2-44ef601b22d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#TODO: make syntax cleaner\n",
    "# TODO: make as merge - isn't simple merge, so will need to write out as separate effort\n",
    "\n",
    "sql_insert_overwrite = f\"\"\"\n",
    "INSERT OVERWRITE {pubmed.processed_articles_content.name}\n",
    "SELECT \n",
    "    id,\n",
    "    pmid,\n",
    "    journal,\n",
    "    title,\n",
    "    year,\n",
    "    citation,\n",
    "    content\n",
    "FROM content_src\"\"\"\n",
    "\n",
    "spark.sql(sql_insert_overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaa90c0e-174f-415b-b6c8-0bcd19f18134",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(pubmed.processed_articles_content.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e5c9f15-d4c1-4d7c-8784-8b86f93d5ff1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# DISCOVERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10f6756f-3ab2-4a46-9c6b-6c4a431c7834",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from unstructured.partition.xml import partition_xml\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "#code to capture math exception local\n",
    "\n",
    "def chunk_xml_body(body: str, attrs: dict):\n",
    "    try: \n",
    "        xml_body = '<root xmlns:xlink=\"http://www.w3.org/1999/xlink\">'+ body + '</root>'\n",
    "        #print(xml_body)\n",
    "        body_elements = partition_xml(text=xml_body,\n",
    "                                xml_keep_tags = False,\n",
    "                                encoding='utf-8',\n",
    "                                include_metadata=False,\n",
    "                                languages=['eng',],\n",
    "                                date_from_file_object=None,\n",
    "                                chunking_strategy='by_title',\n",
    "                                multipage_sections=True,\n",
    "                                combine_text_under_n_chars=300,\n",
    "                                new_after_n_chars=1400,\n",
    "                                max_characters=1250)    \n",
    "        body_chunks = [str(be.text) for be in body_elements if len(be.text) >= 110]\n",
    "        #print(body_chunks)\n",
    "        return [None]\n",
    "    except:\n",
    "        return [str(body),]\n",
    "\n",
    "chunk_xml_body_err_cap_udf = udf(chunk_xml_body_err_cap, ArrayType(StringType()))\n",
    "\n",
    "from pyspark.sql.functions import col, lit, concat\n",
    "from pyspark.sql.functions import xpath_string, explode, posexplode\n",
    "\n",
    "# This includes limit for discussion, real workload will not include a limit\n",
    "content_cap = pubmed.curated_articles.df.limit(100) \\\n",
    "                    .withColumn('contents', chunk_xml_body_err_cap_udf('body')) \\\n",
    "                    .select(col('AccessionID').alias('pmid'),\n",
    "                            xpath_string(col('front'),lit('front/article-meta/title-group/article-title')).alias('title'),\n",
    "                            xpath_string(col('front'),lit('front/journal-meta/journal-title-group/journal-title')).alias('journal'),\n",
    "                            lit('NEED DESIRED CITATION FORMAT').alias('citation'),\n",
    "                            xpath_string(col('front'),lit('front/article-meta/pub-date/year')).alias('year'),\n",
    "                            posexplode('contents').alias('content_pos', 'content')) \\\n",
    "                    .withColumn('id', concat(col('pmid'), lit('-'), col('content_pos'))) \\\n",
    "                    .drop('content_pos') \\\n",
    "                    .alias('cap')\n",
    "\n",
    "\n",
    "display(content_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4b7079c-03d3-41d0-8726-c39995d4b7fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7e25e8b-332c-4a22-a879-ec1ae1975866",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dat = spark.sql('select * from `pubmed-pipeline`.curated.articles_xml WHERE AccessionID = \"PMC11098454\"').collect()[0]\n",
    "attrs = dat.attrs\n",
    "body = dat.body\n",
    "processing_metadata = dat.processing_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a8615de-af47-4adc-9e43-0eddf73e906b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "processing_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cef6b1da-4c29-4909-ab75-6945b1e9eb54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from unstructured.partition.xml import partition_xml\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def chunk_xml_body(body: str, attrs: dict):\n",
    "    root = ET.Element('root', attrib=attrs)\n",
    "    root.text = body\n",
    "    body_elements = partition_xml(text=str(ET.tostring(root, encoding='utf-8'), 'UTF-8'),\n",
    "                                  xml_keep_tags = False,\n",
    "                                  encoding='utf-8',\n",
    "                                  include_metadata=False,\n",
    "                                  languages=['eng',],\n",
    "                                  date_from_file_object=None,\n",
    "                                  chunking_strategy='by_title',\n",
    "                                  multipage_sections=True,\n",
    "                                  combine_text_under_n_chars=300,\n",
    "                                  new_after_n_chars=1400,\n",
    "                                  max_characters=1250)\n",
    "    body_chunks = [be.text for be in body_elements if len(be.text) >= 110]\n",
    "    return body_chunks\n",
    "\n",
    "chunk_xml_body(body, attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5877870c-985b-4e75-aec1-376a08d40f91",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbba37a9-dc1f-47d7-ab75-a96dd89ffa29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "root = ET.Element('root', attrib=attrs)\n",
    "root.text = body\n",
    "xml_body = str(ET.tostring(root, encoding='utf-8'), 'UTF-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05544935-dbb5-43ce-a4f4-c8a2fc059b67",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "xml_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5cbbd34-7d6a-4fd8-87a3-19e6ee2f05d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create the root element\n",
    "\n",
    "\n",
    "# Create a child element\n",
    "child1 = ET.SubElement(root, 'element1')\n",
    "child1.text = 'Content of element1'\n",
    "\n",
    "# Create another child element\n",
    "child2 = ET.SubElement(root, 'element2')\n",
    "child2.text = 'Content of element2'\n",
    "\n",
    "# Create the ElementTree object\n",
    "tree = ET.ElementTree(root)\n",
    "\n",
    "# Write to a file\n",
    "tree.write('output.xml', xml_declaration=True, encoding='UTF-8')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3117380467132938,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "04_Chunk_Articles_Content",
   "widgets": {
    "FILE_TYPE": {
     "currentValue": "xml",
     "nuid": "6ae4e989-aa62-40a4-a2ba-887b9d53fc32",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "xml",
      "label": null,
      "name": "FILE_TYPE",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "xml",
        "text"
       ]
      }
     }
    },
    "INSPECT_CONTENT": {
     "currentValue": "true",
     "nuid": "c916cb50-ce03-4067-9790-f7aa6f00e0b9",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "true",
      "label": null,
      "name": "INSPECT_CONTENT",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "true",
        "false"
       ]
      }
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
